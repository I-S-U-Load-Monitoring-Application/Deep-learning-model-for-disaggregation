{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b63e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_appliance = {\n",
    "    'kettle': {\n",
    "        'windowlength': 599,\n",
    "        'on_power_threshold': 2000,\n",
    "        'max_on_power': 3998,\n",
    "        'mean': 700,\n",
    "        'std': 1000,\n",
    "        's2s_length': 128,\n",
    "        'houses': [1, 2],\n",
    "        'channels': [10, 8],\n",
    "        'train_build': [1],\n",
    "        'test_build': 2,\n",
    "    },\n",
    "    'microwave': {\n",
    "        'windowlength': 599,\n",
    "        'on_power_threshold': 200,\n",
    "        'max_on_power': 3969,\n",
    "        'mean': 500,\n",
    "        'std': 800,\n",
    "        's2s_length': 128,\n",
    "        'houses': [1, 2],\n",
    "        'channels': [13, 15],\n",
    "        'train_build': [1],\n",
    "        'test_build': 2,\n",
    "    },\n",
    "    'fridge': {\n",
    "        'windowlength': 599,\n",
    "        'on_power_threshold': 50,\n",
    "        'max_on_power': 3323,\n",
    "        'mean': 200,\n",
    "        'std': 400,\n",
    "        's2s_length': 512,\n",
    "        'houses': [1, 2],\n",
    "        'channels': [12, 14],\n",
    "        'train_build': [1],\n",
    "        'test_build': 2,\n",
    "    },\n",
    "    \n",
    "   # 'television': { \n",
    "   #     'windowlength': 599,  # You may keep or adjust this\n",
    "   #     'on_power_threshold': 10,\n",
    "   #     'max_on_power': ?,     # To be calculated from meter data\n",
    "   #     'mean': ?,             # Requires usage data\n",
    "   #     'std': ?,              # Requires usage data\n",
    "   #     's2s_length': ?,       # Typical sequence length for s2s models\n",
    "   #     'houses': [1],\n",
    "   #     'channels': [7],\n",
    "   #     'train_build': [1],\n",
    "   #     'test_build': []\n",
    "   # }\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "DATA_DIRECTORY = 'dataset/ukdale/'\n",
    "SAVE_PATH = 'ukdale_seq2point/microwave/'\n",
    "AGG_MEAN = 522\n",
    "AGG_STD = 814\n",
    "APPLIANCE_NAME = 'microwave'\n",
    "\n",
    "\n",
    "\n",
    "mains_data = {\n",
    "    \"mean\": 522,\n",
    "    \"std\":  814        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae31f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_dataframe(directory, building, channel, col_names=['time', 'data'], nrows=None):\n",
    "    df = pd.read_table(directory + 'house_' + str(building) + '/' + 'channel_' +\n",
    "                       str(channel) + '.dat',\n",
    "                       sep=\"\\s+\",\n",
    "                       nrows=nrows,\n",
    "                       usecols=[0, 1],\n",
    "                       names=col_names,\n",
    "                       dtype={'time': str},\n",
    "                       )\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "training_directory=\"refit/microwave/microwave_training_.csv\"\n",
    "validation_directory=\"refit/microwave/microwave_validation_H17.csv\"\n",
    "save_model_dir=\"saved_models/ukdale_models/\"\n",
    "\n",
    "\n",
    "\n",
    "class get_arguments:\n",
    "    def __init__(self):\n",
    "        self.data_dir = DATA_DIRECTORY\n",
    "        self.appliance_name = APPLIANCE_NAME\n",
    "        self.aggregate_mean = 522\n",
    "        self.aggregate_std = 814\n",
    "        self.save_path = SAVE_PATH\n",
    "        self.batch_size = 1000\n",
    "        self.crop = 500000\n",
    "        self.prunning_algorithm = \"threshold\"\n",
    "        self.network_type = \"seq2point\"\n",
    "        self.epochs = 20\n",
    "        self.input_window_length = 599\n",
    "        self.validation_frequency = 1\n",
    "\n",
    "\n",
    "args = get_arguments()\n",
    "appliance_name = args.appliance_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0ebc6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:86: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:86: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6124\\840787682.py:86: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if training_building_percent is not 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dataset/ukdale/house_1/channel_13.dat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6124\\840787682.py:25: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  mains_df['time'] = pd.to_datetime(mains_df['time'], unit='s')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6124\\840787682.py:38: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  app_df['time'] = pd.to_datetime(app_df['time'], unit='s')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6124\\840787682.py:53: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  resample(str(sample_seconds) + 'S').mean().fillna(method='backfill', limit=1)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6124\\840787682.py:52: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_align = mains_df.join(app_df, how='outer'). \\\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6124\\840787682.py:82: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train = pd.concat([train, df_align], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dataset/ukdale/house_2/channel_15.dat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6124\\840787682.py:25: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  mains_df['time'] = pd.to_datetime(mains_df['time'], unit='s')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6124\\840787682.py:38: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  app_df['time'] = pd.to_datetime(app_df['time'], unit='s')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6124\\840787682.py:53: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  resample(str(sample_seconds) + 'S').mean().fillna(method='backfill', limit=1)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6124\\840787682.py:52: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_align = mains_df.join(app_df, how='outer'). \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Size of test set is 1.2936 M rows.\n",
      "    Size of total training set is 0.7261 M rows.\n",
      "    Size of total validation set is 0.1085 M rows.\n",
      "\n",
      "Please find files in: ukdale_seq2point/microwave/\n",
      "Total elapsed time: 22.56 min.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    start_time = time.time()\n",
    "    sample_seconds = 8\n",
    "    training_building_percent = 95\n",
    "    validation_percent = 13\n",
    "    nrows = None\n",
    "    debug = False\n",
    "\n",
    "    train = pd.DataFrame(columns=['aggregate', appliance_name])\n",
    "\n",
    "    for h in params_appliance[appliance_name]['houses']:\n",
    "        print('    ' + args.data_dir + 'house_' + str(h) + '/'\n",
    "              + 'channel_' +\n",
    "              str(params_appliance[appliance_name]['channels'][params_appliance[appliance_name]['houses'].index(h)]) +\n",
    "              '.dat')\n",
    "\n",
    "        mains_df = load_dataframe(args.data_dir, h, 1)\n",
    "        app_df = load_dataframe(args.data_dir,\n",
    "                                h,\n",
    "                                params_appliance[appliance_name]['channels'][params_appliance[appliance_name]['houses'].index(h)],\n",
    "                                col_names=['time', appliance_name]\n",
    "                                )\n",
    "\n",
    "        mains_df['time'] = pd.to_datetime(mains_df['time'], unit='s')\n",
    "        mains_df.set_index('time', inplace=True)\n",
    "        mains_df.columns = ['aggregate']\n",
    "        #resample = mains_df.resample(str(sample_seconds) + 'S').mean()\n",
    "        mains_df.reset_index(inplace=True)\n",
    "\n",
    "        if debug:\n",
    "            print(\"    mains_df:\")\n",
    "            print(mains_df.head())\n",
    "            plt.plot(mains_df['time'], mains_df['aggregate'])\n",
    "            plt.show()\n",
    "\n",
    "        # Appliance\n",
    "        app_df['time'] = pd.to_datetime(app_df['time'], unit='s')\n",
    "\n",
    "        if debug:\n",
    "            print(\"app_df:\")\n",
    "            print(app_df.head())\n",
    "            plt.plot(app_df['time'], app_df[appliance_name])\n",
    "            plt.show()\n",
    "\n",
    "        # the timestamps of mains and appliance are not the same, we need to align them\n",
    "        # 1. join the aggragte and appliance dataframes;\n",
    "        # 2. interpolate the missing values;\n",
    "        mains_df.set_index('time', inplace=True)\n",
    "        app_df.set_index('time', inplace=True)\n",
    "\n",
    "        df_align = mains_df.join(app_df, how='outer'). \\\n",
    "            resample(str(sample_seconds) + 'S').mean().fillna(method='backfill', limit=1)\n",
    "        df_align = df_align.dropna()\n",
    "\n",
    "        df_align.reset_index(inplace=True)\n",
    "\n",
    "        del mains_df, app_df, df_align['time']\n",
    "\n",
    "        if debug:\n",
    "            # plot the dtaset\n",
    "            print(\"df_align:\")\n",
    "            print(df_align.head())\n",
    "            plt.plot(df_align['aggregate'].values)\n",
    "            plt.plot(df_align[appliance_name].values)\n",
    "            plt.show()\n",
    "\n",
    "        # Normilization ----------------------------------------------------------------------------------------------\n",
    "        mean = params_appliance[appliance_name]['mean']\n",
    "        std = params_appliance[appliance_name]['std']\n",
    "\n",
    "        df_align['aggregate'] = (df_align['aggregate'] - args.aggregate_mean) / args.aggregate_std\n",
    "        df_align[appliance_name] = (df_align[appliance_name] - mean) / std\n",
    "\n",
    "        if h == params_appliance[appliance_name]['test_build']:\n",
    "            # Test CSV\n",
    "            df_align.to_csv(args.save_path + appliance_name + '_test_.csv', mode='a', index=False, header=False)\n",
    "            print(\"    Size of test set is {:.4f} M rows.\".format(len(df_align) / 10 ** 6))\n",
    "            continue\n",
    "\n",
    "        \n",
    "        train = pd.concat([train, df_align], ignore_index=True)\n",
    "        del df_align\n",
    "\n",
    "    # Crop dataset\n",
    "    if training_building_percent is not 0:\n",
    "        train.drop(train.index[-int((len(train)/100)*training_building_percent):], inplace=True)\n",
    "\n",
    "\n",
    "    # Validation CSV\n",
    "    val_len = int((len(train)/100)*validation_percent)\n",
    "    val = train.tail(val_len)\n",
    "    val.reset_index(drop=True, inplace=True)\n",
    "    train.drop(train.index[-val_len:], inplace=True)\n",
    "    # Validation CSV\n",
    "    val.to_csv(args.save_path + appliance_name + '_validation_' + '.csv', mode='a', index=False, header=False)\n",
    "\n",
    "    # Training CSV\n",
    "    train.to_csv(args.save_path + appliance_name + '_training_.csv', mode='a', index=False, header=False)\n",
    "\n",
    "    print(\"    Size of total training set is {:.4f} M rows.\".format(len(train) / 10 ** 6))\n",
    "    print(\"    Size of total validation set is {:.4f} M rows.\".format(len(val) / 10 ** 6))\n",
    "    del train, val\n",
    "\n",
    "\n",
    "    print(\"\\nPlease find files in: \" + args.save_path)\n",
    "    print(\"Total elapsed time: {:.2f} min.\".format((time.time() - start_time) / 60))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "604dc0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting creating testset...\n",
      "dataset/ukdale/house_1/channel_13.dat\n",
      "         time  microwave\n",
      "0  1355523693          1\n",
      "1  1355523699          1\n",
      "2  1355523705          1\n",
      "3  1355523711          1\n",
      "4  1355523717          1\n",
      "         time  microwave\n",
      "0  1352500095        599\n",
      "1  1352500101        582\n",
      "2  1352500107        600\n",
      "3  1352500113        586\n",
      "4  1352500120        596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6448\\500205128.py:57: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6448\\500205128.py:58: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  agg_df['time'] = pd.to_datetime(agg_df['time'], unit='ms')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     time  microwave\n",
      "0 1970-01-16 15:41:40.095        599\n",
      "1 1970-01-16 15:41:40.101        582\n",
      "2 1970-01-16 15:41:40.107        600\n",
      "3 1970-01-16 15:41:40.113        586\n",
      "4 1970-01-16 15:41:40.120        596\n",
      "                     time  microwave\n",
      "0 1970-01-16 16:32:03.693          1\n",
      "1 1970-01-16 16:32:03.699          1\n",
      "2 1970-01-16 16:32:03.705          1\n",
      "3 1970-01-16 16:32:03.711          1\n",
      "4 1970-01-16 16:32:03.717          1\n",
      "   aggregate  microwave\n",
      "0        599          1\n",
      "1        582          1\n",
      "2        600          1\n",
      "3        586          1\n",
      "4        596          1\n",
      "                     aggregate  microwave\n",
      "1970-01-01 00:00:00      590.5        1.0\n",
      "1970-01-01 00:00:08      600.0        1.0\n",
      "1970-01-01 00:00:16      586.0        1.0\n",
      "1970-01-01 00:00:24      588.5        1.0\n",
      "1970-01-01 00:00:32      597.0        1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6448\\500205128.py:72: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  ind = pd.date_range(0,  periods=df.shape[0], freq='6S')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6448\\500205128.py:74: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  resample = df.resample('8S')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test set is 0.075 M rows (House 1).\n",
      "dataset/ukdale/house_2/channel_15.dat\n",
      "         time  microwave\n",
      "0  1369085319          0\n",
      "1  1369085325          0\n",
      "2  1369085331          0\n",
      "3  1369085337          0\n",
      "4  1369085344          0\n",
      "         time  microwave\n",
      "0  1361117854        340\n",
      "1  1361117860        341\n",
      "2  1361117866        347\n",
      "3  1361117872        350\n",
      "4  1361117878        342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6448\\500205128.py:57: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6448\\500205128.py:58: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  agg_df['time'] = pd.to_datetime(agg_df['time'], unit='ms')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     time  microwave\n",
      "0 1970-01-16 18:05:17.854        340\n",
      "1 1970-01-16 18:05:17.860        341\n",
      "2 1970-01-16 18:05:17.866        347\n",
      "3 1970-01-16 18:05:17.872        350\n",
      "4 1970-01-16 18:05:17.878        342\n",
      "                     time  microwave\n",
      "0 1970-01-16 20:18:05.319          0\n",
      "1 1970-01-16 20:18:05.325          0\n",
      "2 1970-01-16 20:18:05.331          0\n",
      "3 1970-01-16 20:18:05.337          0\n",
      "4 1970-01-16 20:18:05.344          0\n",
      "   aggregate  microwave\n",
      "0        340          0\n",
      "1        341          0\n",
      "2        347          0\n",
      "3        350          0\n",
      "4        342          0\n",
      "                     aggregate  microwave\n",
      "1970-01-01 00:00:00      340.5        0.0\n",
      "1970-01-01 00:00:08      347.0        0.0\n",
      "1970-01-01 00:00:16      350.0        0.0\n",
      "1970-01-01 00:00:24      341.5        0.0\n",
      "1970-01-01 00:00:32      343.0        0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6448\\500205128.py:72: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  ind = pd.date_range(0,  periods=df.shape[0], freq='6S')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6448\\500205128.py:74: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  resample = df.resample('8S')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test set is 0.075 M rows (House 2).\n",
      "\n",
      "Normalization parameters: \n",
      "Mean and standard deviation values USED for AGGREGATE are:\n",
      "    Mean = 814, STD = 522\n",
      "Mean and standard deviation values USED for microwave are:\n",
      "    Mean = 500, STD = 800\n",
      "\n",
      "Please find files in: ukdale_seq2point/microwave/\n",
      "\n",
      "Total elapsed time: 0 min\n"
     ]
    }
   ],
   "source": [
    "nrows = 10**5\n",
    "path = DATA_DIRECTORY \n",
    "save_path = SAVE_PATH\n",
    "aggregate_std = AGG_MEAN \n",
    "aggregate_mean = AGG_STD\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "def load(path, building, appliance, channel, nrows=None):\n",
    "    # load csv\n",
    "    file_name = path + 'house_' + str(building) + '/' + 'channel_' + str(channel) + '.dat'\n",
    "    single_csv = pd.read_csv(file_name,\n",
    "                             sep=' ',\n",
    "                             #header=0,\n",
    "                             names=['time', appliance],\n",
    "                             dtype={'time': str, \"appliance\": int},\n",
    "                             #parse_dates=['time'],\n",
    "                             #date_parser=pd.to_datetime,\n",
    "                             nrows=nrows,\n",
    "                             usecols=[0, 1],\n",
    "                             engine='python'\n",
    "                             )\n",
    "    return single_csv\n",
    "\n",
    "\n",
    "\n",
    "print(\"Starting creating testset...\")\n",
    "\n",
    "for h in params_appliance[appliance_name]['houses']:\n",
    "\n",
    "    print(path + 'house_' + str(h) + '/'\n",
    "          + 'channel_' +\n",
    "          str(params_appliance[appliance_name]['channels'][params_appliance[appliance_name]['houses'].index(h)]) +\n",
    "          '.dat')\n",
    "\n",
    "    agg_df = load(path,\n",
    "                  h,\n",
    "                  appliance_name,\n",
    "                  1,\n",
    "                  nrows=nrows,\n",
    "                  )\n",
    "\n",
    "    df = load(path,\n",
    "              h,\n",
    "              appliance_name,\n",
    "              params_appliance[appliance_name]['channels'][params_appliance[appliance_name]['houses'].index(h)],\n",
    "              nrows=nrows,\n",
    "              )\n",
    "\n",
    "    #for i in range(100):\n",
    "    #    print(int(df['time'][i]) - int(agg_df['time'][i]))\n",
    "\n",
    "    # Time conversion\n",
    "    print(df.head())\n",
    "    print(agg_df.head())\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "    agg_df['time'] = pd.to_datetime(agg_df['time'], unit='ms')\n",
    "    print(agg_df.head())\n",
    "    print(df.head())\n",
    "\n",
    "    df['aggregate'] = agg_df[appliance_name]\n",
    "    cols = df.columns.tolist()\n",
    "    del cols[0]\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "\n",
    "    print(df.head())\n",
    "\n",
    "\n",
    "    # Re-sampling\n",
    "    ind = pd.date_range(0,  periods=df.shape[0], freq='6S')\n",
    "    df.set_index(ind, inplace=True, drop=True)\n",
    "    resample = df.resample('8S')\n",
    "    df = resample.mean()\n",
    "\n",
    "    print(df.head())\n",
    "\n",
    "    # Normalization\n",
    "    df['aggregate'] = (df['aggregate'] - aggregate_mean) / aggregate_std\n",
    "    df[appliance_name] = \\\n",
    "        (df[appliance_name] - params_appliance[appliance_name]['mean']) / params_appliance[appliance_name]['std']\n",
    "\n",
    "    # Save\n",
    "    df.to_csv(save_path + appliance_name + '_test_' + 'uk-dale_' + 'H' + str(h) + '.csv', index=False)\n",
    "\n",
    "    print(\"Size of test set is {:.3f} M rows (House {:d}).\"\n",
    "          .format(df.shape[0] / 10 ** 6, h))\n",
    "\n",
    "    del df\n",
    "\n",
    "\n",
    "print(\"\\nNormalization parameters: \")\n",
    "print(\"Mean and standard deviation values USED for AGGREGATE are:\")\n",
    "print(\"    Mean = {:d}, STD = {:d}\".format(aggregate_mean, aggregate_std))\n",
    "\n",
    "print('Mean and standard deviation values USED for ' + appliance_name + ' are:')\n",
    "print(\"    Mean = {:d}, STD = {:d}\"\n",
    "      .format(params_appliance[appliance_name]['mean'], params_appliance[appliance_name]['std']))\n",
    "\n",
    "print(\"\\nPlease find files in: \" + save_path)\n",
    "tot = int(int(time.time() - start_time) / 60)\n",
    "print(\"\\nTotal elapsed time: \" + str(tot) + ' min')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b9788",
   "metadata": {},
   "source": [
    "Data Feeder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5447e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# batch_size: the number of rows fed into the network at once.\n",
    "# crop: the number of rows in the data set to be used in total.\n",
    "# chunk_size: the number of lines to read from the file at once.\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "class TrainSlidingWindowGenerator():\n",
    "    \"\"\"Fixed Yields features and targets for training a ConvNet.\n",
    "\n",
    "    Parameters:\n",
    "    __file_name (string): The path where the training dataset is located.\n",
    "    __batch_size (int): The size of each batch from the dataset to be processed.\n",
    "    __chunk_size (int): The size of each chunk of data to be processed.\n",
    "    __shuffle (bool): Whether the dataset should be shuffled before being returned.\n",
    "    __offset (int): Half window size for sequence-to-point\n",
    "    __crop (int): The number of rows of the dataset to return.\n",
    "    __skip_rows (int): The number of rows of a dataset to skip before reading data.\n",
    "    __ram_threshold (int): The maximum amount of RAM to utilise at a time.\n",
    "    total_size (int): The number of rows read from the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                file_name, \n",
    "                chunk_size, \n",
    "                shuffle, \n",
    "                offset, \n",
    "                batch_size=1000, \n",
    "                crop=500000,  # Increased from 10K to 500K\n",
    "                skip_rows=0,  # Don't skip rows by default\n",
    "                ram_threshold=5 * 10 ** 5):\n",
    "        self.__file_name = file_name\n",
    "        self.__batch_size = batch_size\n",
    "        self.__chunk_size = chunk_size\n",
    "        self.__shuffle = shuffle\n",
    "        self.__offset = offset\n",
    "        self.__crop = crop\n",
    "        self.__skip_rows = skip_rows\n",
    "        self.__ram_threshold = ram_threshold\n",
    "        self.__total_size = 0\n",
    "        self.__total_num_samples = crop\n",
    "\n",
    "    @property\n",
    "    def total_num_samples(self):\n",
    "        return self.__total_num_samples\n",
    "    \n",
    "    @total_num_samples.setter\n",
    "    def total_num_samples(self, value):\n",
    "        self.__total_num_samples = value\n",
    "\n",
    "    def check_if_chunking(self):\n",
    "        \"\"\"Count the number of rows in the dataset and determine whether this is larger than the chunking \n",
    "        threshold or not.\"\"\"\n",
    "\n",
    "        print(\"Importing training file...\")\n",
    "        chunks = pd.read_csv(self.__file_name, \n",
    "                            header=0, \n",
    "                            nrows=self.__crop, \n",
    "                            skiprows=self.__skip_rows, \n",
    "                            skip_blank_lines=True)\n",
    "        print(\"Counting number of rows...\")\n",
    "        self.__total_size = len(chunks)\n",
    "        del chunks\n",
    "        print(\"Done.\")\n",
    "\n",
    "        print(\"The dataset contains \", self.__total_size, \" rows\")\n",
    "\n",
    "        if (self.__total_size > self.__ram_threshold):\n",
    "            print(\"There is too much data to load into memory, so it will be loaded in chunks.\")\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        \"\"\"Fixed version: Yields pairs of features and targets for neural network training.\n",
    "\n",
    "        Yields:\n",
    "        input_data (numpy.array): A 3D array of shape (batch_size, window_length, 1) \n",
    "        output_data (numpy.array): A 2D array of shape (batch_size, 1) containing target values\n",
    "        \"\"\"\n",
    "\n",
    "        if self.__total_size == 0:\n",
    "            self.check_if_chunking()\n",
    "\n",
    "        # If the data can be loaded in one go\n",
    "        if (self.__total_size <= self.__ram_threshold):\n",
    "            print(\"Loading all data into memory...\")\n",
    "            \n",
    "            # Load the CSV data\n",
    "            data_array = np.array(pd.read_csv(self.__file_name, \n",
    "                                            nrows=self.__crop, \n",
    "                                            skiprows=self.__skip_rows, \n",
    "                                            header=0, \n",
    "                                            skip_blank_lines=True))\n",
    "            \n",
    "            # Separate inputs (aggregate power) and outputs (appliance power)\n",
    "            inputs = data_array[:, 0]   # Aggregate power\n",
    "            outputs = data_array[:, 1]  # Appliance power\n",
    "\n",
    "            # Calculate valid sample range (need full windows)\n",
    "            window_length = 2 * self.__offset + 1  # Total window length\n",
    "            maximum_batch_size = len(inputs) - window_length + 1\n",
    "            self.total_num_samples = maximum_batch_size\n",
    "            \n",
    "            if self.__batch_size < 0:\n",
    "                self.__batch_size = maximum_batch_size\n",
    "\n",
    "            print(f\"Window length: {window_length}\")\n",
    "            print(f\"Total samples available: {maximum_batch_size}\")\n",
    "            print(f\"Batch size: {self.__batch_size}\")\n",
    "\n",
    "            # Create indices for sampling\n",
    "            indices = np.arange(maximum_batch_size)\n",
    "            if self.__shuffle:\n",
    "                np.random.shuffle(indices)\n",
    "\n",
    "            # Infinite generator loop\n",
    "            while True:\n",
    "                for start_index in range(0, maximum_batch_size, self.__batch_size):\n",
    "                    end_index = min(start_index + self.__batch_size, maximum_batch_size)\n",
    "                    batch_indices = indices[start_index:end_index]\n",
    "                    \n",
    "                    # Create input windows\n",
    "                    input_data = np.array([\n",
    "                        inputs[idx:idx + window_length] \n",
    "                        for idx in batch_indices\n",
    "                    ])\n",
    "                    \n",
    "                    # Get corresponding output values (center of window)\n",
    "                    output_data = np.array([\n",
    "                        outputs[idx + self.__offset] \n",
    "                        for idx in batch_indices\n",
    "                    ])\n",
    "                    \n",
    "                    # Reshape for CNN: (batch_size, window_length, 1)\n",
    "                    input_data = input_data.reshape(-1, window_length, 1)\n",
    "                    output_data = output_data.reshape(-1, 1)\n",
    "                    \n",
    "                    yield input_data, output_data\n",
    "                    \n",
    "                # Reshuffle for next epoch\n",
    "                if self.__shuffle:\n",
    "                    np.random.shuffle(indices)\n",
    "                    \n",
    "        else:\n",
    "            # Handle chunked loading (for very large datasets)\n",
    "            print(\"Loading data in chunks...\")\n",
    "            \n",
    "            chunk_starts = np.arange(0, self.__total_size, self.__chunk_size)\n",
    "            if self.__shuffle:\n",
    "                np.random.shuffle(chunk_starts)\n",
    "\n",
    "            for chunk_start in chunk_starts:\n",
    "                # Load chunk\n",
    "                chunk_size = min(self.__chunk_size, self.__total_size - chunk_start)\n",
    "                data_array = np.array(pd.read_csv(\n",
    "                    self.__file_name, \n",
    "                    skiprows=self.__skip_rows + chunk_start, \n",
    "                    header=0 if chunk_start == 0 else None,\n",
    "                    nrows=chunk_size, \n",
    "                    skip_blank_lines=True\n",
    "                ))\n",
    "                \n",
    "                inputs = data_array[:, 0]\n",
    "                outputs = data_array[:, 1]\n",
    "\n",
    "                window_length = 2 * self.__offset + 1\n",
    "                maximum_batch_size = len(inputs) - window_length + 1\n",
    "                \n",
    "                if maximum_batch_size <= 0:\n",
    "                    continue\n",
    "                    \n",
    "                indices = np.arange(maximum_batch_size)\n",
    "                if self.__shuffle:\n",
    "                    np.random.shuffle(indices)\n",
    "\n",
    "                # Process this chunk\n",
    "                for start_index in range(0, maximum_batch_size, self.__batch_size):\n",
    "                    end_index = min(start_index + self.__batch_size, maximum_batch_size)\n",
    "                    batch_indices = indices[start_index:end_index]\n",
    "                    \n",
    "                    input_data = np.array([\n",
    "                        inputs[idx:idx + window_length] \n",
    "                        for idx in batch_indices\n",
    "                    ])\n",
    "                    \n",
    "                    output_data = np.array([\n",
    "                        outputs[idx + self.__offset] \n",
    "                        for idx in batch_indices\n",
    "                    ])\n",
    "                    \n",
    "                    # Reshape for CNN\n",
    "                    input_data = input_data.reshape(-1, window_length, 1)\n",
    "                    output_data = output_data.reshape(-1, 1)\n",
    "                    \n",
    "                    yield input_data, output_data\n",
    "\n",
    "# Test function to verify the generator works\n",
    "  \n",
    "\n",
    "                    \n",
    "class TestSlidingWindowGenerator(object):\n",
    "\n",
    "    \"\"\"Yields features and targets for testing and validating a ConvNet.\n",
    "\n",
    "    Parameters:\n",
    "    __number_of_windows (int): The number of sliding windows to produce.\n",
    "    __offset (int): The offset of the infered value from the sliding window.\n",
    "    __inputs (numpy.ndarray): The available testing / validation features.\n",
    "    __targets (numpy.ndarray): The target values corresponding to __inputs.\n",
    "    __total_size (int): The total number of inputs.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, number_of_windows, inputs, targets, offset):\n",
    "        self.__number_of_windows = number_of_windows\n",
    "        self.__offset = offset\n",
    "        self.__inputs = inputs\n",
    "        self.__targets = targets\n",
    "        self.total_size = len(inputs)\n",
    "\n",
    "    def load_dataset(self):\n",
    "\n",
    "        \"\"\"Yields features and targets for testing and validating a ConvNet.\n",
    "\n",
    "        Yields:\n",
    "        input_data (numpy.array): An array of features to test / validate the network with.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.__inputs = self.__inputs.flatten()\n",
    "        max_number_of_windows = self.__inputs.size - 2 * self.__offset\n",
    "\n",
    "        if self.__number_of_windows < 0:\n",
    "            self.__number_of_windows = max_number_of_windows\n",
    "\n",
    "        indicies = np.arange(max_number_of_windows, dtype=int)\n",
    "        for start_index in range(0, max_number_of_windows, self.__number_of_windows):\n",
    "            splice = indicies[start_index : start_index + self.__number_of_windows]\n",
    "            input_data = np.array([self.__inputs[index : index + 2 * self.__offset + 1] for index in splice])\n",
    "            target_data = self.__targets[splice + self.__offset].reshape(-1, 1)\n",
    "            yield input_data, target_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb862de",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os\n",
    "\n",
    "def create_model(input_window_length):\n",
    "    \"\"\"\n",
    "    Fixed seq2point model for NILM using Conv1D layers.\n",
    "    \n",
    "    Parameters:\n",
    "    input_window_length (int): Length of input sequence (599 for NILM)\n",
    "    \n",
    "    Returns:\n",
    "    model (tensorflow.keras.Model): The compiled seq2point model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input layer - 1D time series\n",
    "    input_layer = tf.keras.layers.Input(shape=(input_window_length, 1))\n",
    "    \n",
    "    # Conv1D layers for time series processing\n",
    "    conv_layer_1 = tf.keras.layers.Conv1D(filters=30, kernel_size=10, \n",
    "                                         strides=1, padding=\"same\", \n",
    "                                         activation=\"relu\")(input_layer)\n",
    "    \n",
    "    conv_layer_2 = tf.keras.layers.Conv1D(filters=30, kernel_size=8, \n",
    "                                         strides=1, padding=\"same\", \n",
    "                                         activation=\"relu\")(conv_layer_1)\n",
    "    \n",
    "    conv_layer_3 = tf.keras.layers.Conv1D(filters=40, kernel_size=6, \n",
    "                                         strides=1, padding=\"same\", \n",
    "                                         activation=\"relu\")(conv_layer_2)\n",
    "    \n",
    "    conv_layer_4 = tf.keras.layers.Conv1D(filters=50, kernel_size=5, \n",
    "                                         strides=1, padding=\"same\", \n",
    "                                         activation=\"relu\")(conv_layer_3)\n",
    "    \n",
    "    conv_layer_5 = tf.keras.layers.Conv1D(filters=50, kernel_size=5, \n",
    "                                         strides=1, padding=\"same\", \n",
    "                                         activation=\"relu\")(conv_layer_4)\n",
    "    \n",
    "    # Add dropout for regularization\n",
    "    dropout_1 = tf.keras.layers.Dropout(0.2)(conv_layer_5)\n",
    "    \n",
    "    # Flatten and dense layers\n",
    "    flatten_layer = tf.keras.layers.Flatten()(dropout_1)\n",
    "    dense_layer = tf.keras.layers.Dense(1024, activation=\"relu\")(flatten_layer)\n",
    "    dropout_2 = tf.keras.layers.Dropout(0.2)(dense_layer)\n",
    "    \n",
    "    # Output layer for regression\n",
    "    output_layer = tf.keras.layers.Dense(1, activation=\"linear\")(dropout_2)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "def save_model(model, network_type, algorithm, appliance, save_model_dir):\n",
    "\n",
    "    \"\"\" Saves a model to a specified location. Models are named using a combination of their \n",
    "    target appliance, architecture, and pruning algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    model (tensorflow.keras.Model): The Keras model to save.\n",
    "    network_type (string): The architecture of the model ('', 'reduced', 'dropout', or 'reduced_dropout').\n",
    "    algorithm (string): The pruning algorithm applied to the model.\n",
    "    appliance (string): The appliance the model was trained with.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #model_path = \"saved_models/\" + appliance + \"_\" + algorithm + \"_\" + network_type + \"_model.h5\"\n",
    "    model_path = save_model_dir\n",
    "\n",
    "    if not os.path.exists (model_path):\n",
    "        open((model_path), 'a').close()\n",
    "\n",
    "    model.save(model_path)\n",
    "\n",
    "def load_model(model, network_type, algorithm, appliance, saved_model_dir):\n",
    "\n",
    "    \"\"\" Loads a model from a specified location.\n",
    "\n",
    "    Parameters:\n",
    "    model (tensorflow.keras.Model): The Keas model to which the loaded weights will be applied to.\n",
    "    network_type (string): The architecture of the model ('', 'reduced', 'dropout', or 'reduced_dropout').\n",
    "    algorithm (string): The pruning algorithm applied to the model.\n",
    "    appliance (string): The appliance the model was trained with.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #model_name = \"saved_models/\" + appliance + \"_\" + algorithm + \"_\" + network_type + \"_model.h5\"\n",
    "    model_name = saved_model_dir\n",
    "    print(\"PATH NAME: \", model_name)\n",
    "\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    num_of_weights = model.count_params()\n",
    "    print(\"Loaded model with \", str(num_of_weights), \" weights\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ac96e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_space(string):\n",
    "    return string.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f6d7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "class Trainer():\n",
    "\n",
    "    \"\"\" Used to train a seq2point model with or without pruning applied Supports \n",
    "    various alternative architectures. \n",
    "    \n",
    "    Parameters:\n",
    "    __appliance (string): The target appliance.\n",
    "    __network_type (string): The architecture of the model.\n",
    "    __batch_size (int): The number of rows per testing batch.\n",
    "    __window_size (int): The size of eaech sliding window\n",
    "    __window_offset (int): The offset of the inferred value from the sliding window.\n",
    "    __max_chunk_size (int): The largest possible number of row per chunk.\n",
    "    __validation_frequency (int): The number of epochs between model validation.\n",
    "    __training_directory (string): The directory of the model's training file.\n",
    "    __validation_directory (string): The directory of the model's validation file.\n",
    "    __training_chunker (TrainSlidingWindowGenerator): A sliding window provider \n",
    "    that returns feature / target pairs. For training use only.\n",
    "    __validation_chunker (TrainSlidingWindowGenerator): A sliding window provider \n",
    "    that returns feature / target pairs. For validation use only.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, appliance, batch_size, crop, network_type, \n",
    "                 training_directory, validation_directory, save_model_dir,\n",
    "                 epochs=10, input_window_length=599, validation_frequency = 1,\n",
    "                 patience=3, min_delta=1e-6, verbose=1):\n",
    "        self.__appliance = appliance\n",
    "        self.__algorithm = network_type\n",
    "        self.__network_type = network_type\n",
    "        self.__crop = crop\n",
    "        self.__batch_size = batch_size\n",
    "        self.__epochs = epochs\n",
    "        self.__patience = patience\n",
    "        self.__min_delta = min_delta\n",
    "        self.__verbose = verbose\n",
    "        self.__loss = \"mse\"\n",
    "        self.__metrics = [\"mse\", \"msle\", \"mae\"]\n",
    "        self.__learning_rate = 0.001\n",
    "        self.__beta_1=0.9\n",
    "        self.__beta_2=0.999\n",
    "        self.__save_model_dir = save_model_dir\n",
    "\n",
    "        self.__input_window_length = input_window_length\n",
    "        self.__window_size = 2+self.__input_window_length\n",
    "        self.__window_offset = int((0.5 * self.__window_size) - 1)\n",
    "        self.__max_chunk_size = 5 * 10 ** 2\n",
    "        self.__validation_frequency = validation_frequency\n",
    "        self.__ram_threshold=5*10**5\n",
    "        self.__skip_rows_train=0\n",
    "        self.__validation_steps=100\n",
    "        self.__skip_rows_val = 0\n",
    "\n",
    "        # Directories of the training and validation files. Always has the structure \n",
    "        # ./dataset_management/refit/{appliance_name}/{appliance_name}_training_.csv for training or \n",
    "        # ./dataset_management/refit/{appliance_name}/{appliance_name}_validation_.csv\n",
    "        self.__training_directory = training_directory\n",
    "        self.__validation_directory = validation_directory\n",
    "\n",
    "        self.__training_chunker = TrainSlidingWindowGenerator(file_name=self.__training_directory, \n",
    "                                        chunk_size=self.__max_chunk_size, \n",
    "                                        batch_size=self.__batch_size, \n",
    "                                        crop=self.__crop, shuffle=True,\n",
    "                                        skip_rows=self.__skip_rows_train, \n",
    "                                        offset=self.__window_offset, \n",
    "                                        ram_threshold=self.__ram_threshold)\n",
    "        self.__validation_chunker = TrainSlidingWindowGenerator(file_name=self.__validation_directory, \n",
    "                                            chunk_size=self.__max_chunk_size, \n",
    "                                            batch_size=self.__batch_size, \n",
    "                                            crop=self.__crop, \n",
    "                                            shuffle=True,\n",
    "                                            skip_rows=self.__skip_rows_val, \n",
    "                                            offset=self.__window_offset, \n",
    "                                            ram_threshold=self.__ram_threshold)\n",
    "\n",
    "    def train_model(self):\n",
    "\n",
    "        \"\"\" Trains an energy disaggregation model using a user-selected pruning algorithm (default is no pruning). \n",
    "        Plots and saves the resulting model. \"\"\"\n",
    "\n",
    "        # Calculate the optimum steps per epoch.\n",
    "        # self.__training_chunker.check_if_chunking()\n",
    "        #steps_per_training_epoch = np.round(int(self.__training_chunker.total_size / self.__batch_size), decimals=0)\n",
    "        steps_per_training_epoch = np.round(int(self.__training_chunker.total_num_samples / self.__batch_size), decimals=0)\n",
    "        \n",
    "        model = create_model(self.__input_window_length)\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.__learning_rate, beta_1=self.__beta_1, beta_2=self.__beta_2), loss=self.__loss, metrics=self.__metrics) \n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=self.__min_delta, patience=self.__patience, verbose=self.__verbose, mode=\"auto\")\n",
    "\n",
    "        ## can use checkpoint ###############################################\n",
    "        # checkpoint_filepath = \"checkpoint/housedata/refit/\"+ self.__appliance + \"/\"\n",
    "        # model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        #     filepath = checkpoint_filepath,\n",
    "        #     monitor='val_loss',\n",
    "        #     verbose=0,\n",
    "        #     save_best_only=True,\n",
    "        #     save_weights_only=False,\n",
    "        #     mode='auto',\n",
    "        #     save_freq='epoch')        \n",
    "        #callbacks=[early_stopping, model_checkpoint_callback]\n",
    "        ###################################################################\n",
    "\n",
    "        callbacks=[early_stopping]\n",
    "        \n",
    "        training_history = self.default_train(model, callbacks, steps_per_training_epoch)\n",
    "\n",
    "        training_history.history[\"val_loss\"] = np.repeat(training_history.history[\"val_loss\"], self.__validation_frequency)\n",
    "\n",
    "        model.summary()\n",
    "        save_model(model, self.__network_type, self.__algorithm, \n",
    "                   self.__appliance, self.__save_model_dir)\n",
    "        \n",
    "        print(f\"\\n=== MODEL SIZE INFO ===\")\n",
    "        print(f\"Total parameters: {model.count_params():,}\")\n",
    "        print(f\"Expected model size: ~{model.count_params() * 4 / (1024*1024):.1f} MB\")\n",
    "        print(f\"Input shape: {model.input_shape}\")\n",
    "        print(f\"Output shape: {model.output_shape}\")\n",
    "\n",
    "        self.plot_training_results(training_history)\n",
    "\n",
    "    def default_train(self, model, callbacks, steps_per_training_epoch):\n",
    "\n",
    "        \"\"\" The default training method the neural network will use. No pruning occurs.\n",
    "\n",
    "        Parameters:\n",
    "        model (tensorflow.keras.Model): The seq2point model being trained.\n",
    "        early_stopping (tensorflow.keras.callbacks.EarlyStopping): An early stopping callback to \n",
    "        prevent overfitting.\n",
    "        steps_per_training_epoch (int): The number of training steps to occur per epoch.\n",
    "\n",
    "        Returns:\n",
    "        training_history (numpy.ndarray): The error metrics and loss values that were calculated \n",
    "        at the end of each training epoch.\n",
    "\n",
    "        \"\"\"\n",
    "        # ########### this is retired ##############################\n",
    "        # training_history = model.fit_generator(self.__training_chunker.load_dataset(),\n",
    "        #     steps_per_epoch=steps_per_training_epoch,\n",
    "        #     epochs=1,\n",
    "        #     verbose=1,\n",
    "        #     validation_data = self.__validation_chunker.load_dataset(),\n",
    "        #     validation_steps=100,\n",
    "        #     validation_freq=self.__validation_frequency,\n",
    "        #     callbacks=[early_stopping])\n",
    "        ############################################################\n",
    "\n",
    "        training_history = model.fit(self.__training_chunker.load_dataset(),                            \n",
    "                      steps_per_epoch=int(steps_per_training_epoch),\n",
    "                      epochs=self.__epochs,\n",
    "                      verbose=self.__verbose,\n",
    "                      callbacks=callbacks,\n",
    "                      validation_data=self.__validation_chunker.load_dataset(),\n",
    "                      validation_freq=self.__validation_frequency,\n",
    "                      validation_steps=self.__validation_steps)\n",
    "\n",
    "        return training_history\n",
    "\n",
    "    def plot_training_results(self, training_history):\n",
    "\n",
    "        \"\"\" Plots and saves a graph of training loss against epoch.\n",
    "\n",
    "        Parameters:\n",
    "        training_history (numpy.ndarray): A timeseries of loss against epoch count.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        plt.plot(training_history.history[\"loss\"], label=\"MSE (Training Loss)\")\n",
    "        plt.plot(training_history.history[\"val_loss\"], label=\"MSE (Validation Loss)\")\n",
    "        plt.title('Training History')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "\n",
    "        #file_name = \"./\" + self.__appliance + \"/saved_models/\" + self.__appliance + \"_\" + self.__pruning_algorithm + \"_\" + self.__network_type + \"_training_results.png\"\n",
    "        #plt.savefig(fname=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "559549f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np \n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Tester():\n",
    "\n",
    "    \"\"\" Used to test and evaluate a pre-trained seq2point model with or without pruning applied. \n",
    "    \n",
    "    Parameters:\n",
    "    __appliance (string): The target appliance.\n",
    "    __algorithm (string): The (pruning) algorithm the model was trained with.\n",
    "    __network_type (string): The architecture of the model.\n",
    "    __crop (int): The maximum number of rows of data to evaluate the model with.\n",
    "    __batch_size (int): The number of rows per testing batch.\n",
    "    __window_size (int): The size of eaech sliding window\n",
    "    __window_offset (int): The offset of the inferred value from the sliding window.\n",
    "    __test_directory (string): The directory of the test file for the model.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, appliance, algorithm, crop, batch_size, network_type,\n",
    "                 test_directory, saved_model_dir, log_file_dir,\n",
    "                 input_window_length):\n",
    "        self.__appliance = appliance\n",
    "        self.__algorithm = algorithm\n",
    "        self.__network_type = network_type\n",
    "\n",
    "        self.__crop = crop\n",
    "        self.__batch_size = batch_size\n",
    "        self._input_window_length = input_window_length\n",
    "        self.__window_size = self._input_window_length + 2\n",
    "        self.__window_offset = int(0.5 * self.__window_size - 1)\n",
    "        self.__number_of_windows = 100\n",
    "\n",
    "        self.__test_directory = test_directory\n",
    "        self.__saved_model_dir = saved_model_dir\n",
    "\n",
    "        self.__log_file = log_file_dir\n",
    "        logging.basicConfig(filename=self.__log_file,level=logging.INFO)\n",
    "\n",
    "    def test_model(self):\n",
    "\n",
    "        \"\"\" Tests a fully-trained model using a sliding window generator as an input. Measures inference time, gathers, and \n",
    "        plots evaluationg metrics. \"\"\"\n",
    "\n",
    "        test_input, test_target = self.load_dataset(self.__test_directory)\n",
    "        model = create_model(self._input_window_length)\n",
    "        model = load_model(model, self.__network_type, self.__algorithm, \n",
    "                           self.__appliance, self.__saved_model_dir)\n",
    "\n",
    "        test_generator = TestSlidingWindowGenerator(number_of_windows=self.__number_of_windows, inputs=test_input, targets=test_target, offset=self.__window_offset)\n",
    "\n",
    "        # Calculate the optimum steps per epoch.\n",
    "        steps_per_test_epoch = np.round(int(test_generator.total_size / self.__batch_size), decimals=0)\n",
    "\n",
    "        # Test the model.\n",
    "        start_time = time.time()\n",
    "        testing_history = model.predict(x=test_generator.load_dataset(), steps=steps_per_test_epoch, verbose=2)\n",
    "\n",
    "        end_time = time.time()\n",
    "        test_time = end_time - start_time\n",
    "\n",
    "        evaluation_metrics = model.evaluate(x=test_generator.load_dataset(), steps=steps_per_test_epoch)\n",
    "\n",
    "        self.log_results(model, test_time, evaluation_metrics)\n",
    "        self.plot_results(testing_history, test_input, test_target)\n",
    "\n",
    "\n",
    "    def load_dataset(self, directory):\n",
    "        \"\"\"Loads the testing dataset from the location specified by file_name.\n",
    "\n",
    "        Parameters:\n",
    "        directory (string): The location at which the dataset is stored, concatenated with the file name.\n",
    "\n",
    "        Returns:\n",
    "        test_input (numpy.array): The first n (crop) features of the test dataset.\n",
    "        test_target (numpy.array): The first n (crop) targets of the test dataset.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        data_frame = pd.read_csv(directory, nrows=self.__crop, skiprows=0, header=0)\n",
    "        test_input = np.round(np.array(data_frame.iloc[:, 0], float), 6)\n",
    "        test_target = np.round(np.array(data_frame.iloc[self.__window_offset: -self.__window_offset, 1], float), 6)\n",
    "        \n",
    "        del data_frame\n",
    "        return test_input, test_target\n",
    "\n",
    "    def log_results(self, model, test_time, evaluation_metrics):\n",
    "\n",
    "        \"\"\"Logs the inference time, MAE and MSE of an evaluated model.\n",
    "\n",
    "        Parameters:\n",
    "        model (tf.keras.Model): The evaluated model.\n",
    "        test_time (float): The time taken by the model to infer all required values.\n",
    "        evaluation metrics (list): The MSE, MAE, and various compression ratios of the model.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        inference_log = \"Inference Time: \" + str(test_time)\n",
    "        logging.info(inference_log)\n",
    "\n",
    "        metric_string = \"MSE: \", str(evaluation_metrics[0]), \" MAE: \", str(evaluation_metrics[3])\n",
    "        logging.info(metric_string)\n",
    "\n",
    "        self.count_pruned_weights(model)  \n",
    "\n",
    "    def count_pruned_weights(self, model):\n",
    "\n",
    "        \"\"\" Counts the total number of weights, pruned weights, and weights in convolutional \n",
    "        layers. Calculates the sparsity ratio of different layer types and logs these values.\n",
    "\n",
    "        Parameters:\n",
    "        model (tf.keras.Model): The evaluated model.\n",
    "\n",
    "        \"\"\"\n",
    "        num_total_zeros = 0\n",
    "        num_dense_zeros = 0\n",
    "        num_dense_weights = 0\n",
    "        num_conv_zeros = 0\n",
    "        num_conv_weights = 0\n",
    "        for layer in model.layers:\n",
    "            if np.shape(layer.get_weights())[0] != 0:\n",
    "                layer_weights = layer.get_weights()[0].flatten()\n",
    "\n",
    "                if \"conv\" in layer.name:\n",
    "                    num_conv_weights += np.size(layer_weights)\n",
    "                    num_conv_zeros += np.count_nonzero(layer_weights==0)\n",
    "\n",
    "                    num_total_zeros += np.size(layer_weights)\n",
    "                else:\n",
    "                    num_dense_weights += np.size(layer_weights)\n",
    "                    num_dense_zeros += np.count_nonzero(layer_weights==0)\n",
    "\n",
    "        conv_zeros_string = \"CONV. ZEROS: \" + str(num_conv_zeros)\n",
    "        conv_weights_string = \"CONV. WEIGHTS: \" + str(num_conv_weights)\n",
    "        conv_sparsity_ratio = \"CONV. RATIO: \" + str(num_conv_zeros / num_conv_weights)\n",
    "\n",
    "        dense_weights_string = \"DENSE WEIGHTS: \" + str(num_dense_weights)\n",
    "        dense_zeros_string = \"DENSE ZEROS: \" + str(num_dense_zeros)\n",
    "        dense_sparsity_ratio = \"DENSE RATIO: \" + str(num_dense_zeros / num_dense_weights)\n",
    "\n",
    "        total_zeros_string = \"TOTAL ZEROS: \" + str(num_total_zeros)\n",
    "        total_weights_string = \"TOTAL WEIGHTS: \" + str(model.count_params())\n",
    "        total_sparsity_ratio = \"TOTAL RATIO: \" + str(num_total_zeros / model.count_params())\n",
    "\n",
    "        print(\"LOGGING PATH: \", self.__log_file)\n",
    "\n",
    "        logging.info(conv_zeros_string)\n",
    "        logging.info(conv_weights_string)\n",
    "        logging.info(conv_sparsity_ratio)\n",
    "        logging.info(\"\")\n",
    "        logging.info(dense_zeros_string)\n",
    "        logging.info(dense_weights_string)\n",
    "        logging.info(dense_sparsity_ratio)\n",
    "        logging.info(\"\")\n",
    "        logging.info(total_zeros_string)\n",
    "        logging.info(total_weights_string)\n",
    "        logging.info(total_sparsity_ratio)\n",
    "\n",
    "    def plot_results(self, testing_history, test_input, test_target):\n",
    "\n",
    "        \"\"\" Generates and saves a plot of the testing history of the model against the (actual) \n",
    "        aggregate energy values and the true appliance values.\n",
    "\n",
    "        Parameters:\n",
    "        testing_history (numpy.ndarray): The series of values inferred by the model.\n",
    "        test_input (numpy.ndarray): The aggregate energy data.\n",
    "        test_target (numpy.ndarray): The true energy values of the appliance.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        testing_history = ((testing_history * params_appliance[self.__appliance][\"std\"]) + params_appliance[self.__appliance][\"mean\"])\n",
    "        test_target = ((test_target * params_appliance[self.__appliance][\"std\"]) + params_appliance[self.__appliance][\"mean\"])\n",
    "        test_agg = (test_input.flatten() * mains_data[\"std\"]) + mains_data[\"mean\"]\n",
    "        test_agg = test_agg[:testing_history.size]\n",
    "\n",
    "        # Can't have negative energy readings - set any results below 0 to 0.\n",
    "        test_target[test_target < 0] = 0\n",
    "        testing_history[testing_history < 0] = 0\n",
    "        test_input[test_input < 0] = 0\n",
    "\n",
    "        # Plot testing outcomes against ground truth.\n",
    "        plt.figure(1)\n",
    "        plt.plot(test_agg[self.__window_offset: -self.__window_offset], label=\"Aggregate\")\n",
    "        plt.plot(test_target[:test_agg.size - (2 * self.__window_offset)], label=\"Ground Truth\")\n",
    "        plt.plot(testing_history[:test_agg.size - (2 * self.__window_offset)], label=\"Predicted\")\n",
    "        plt.title(self.__appliance + \" \" + self.__network_type + \"(\" + self.__algorithm + \")\")\n",
    "        plt.ylabel(\"Power Value (Watts)\")\n",
    "        plt.xlabel(\"Testing Window\")\n",
    "        plt.legend()\n",
    "\n",
    "        #file_path = \"./\" + self.__appliance + \"/saved_models/\" + self.__appliance + \"_\" + self.__algorithm + \"_\" + self.__network_type + \"_test_figure.png\"\n",
    "        #plt.savefig(fname=file_path)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd317b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing training file...\n",
      "Counting number of rows...\n",
      "Done.\n",
      "The dataset contains  500000  rows\n",
      "Loading all data into memory...\n",
      "Window length: 599\n",
      "Total samples available: 499402\n",
      "Batch size: 1000\n",
      "Epoch 1/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2701 - mse: 0.2701 - msle: 0.0016 - mae: 0.1886Importing training file...\n",
      "Counting number of rows...\n",
      "Done.\n",
      "The dataset contains  500000  rows\n",
      "Loading all data into memory...\n",
      "Window length: 599\n",
      "Total samples available: 499402\n",
      "Batch size: 1000\n",
      "500/500 [==============================] - 269s 512ms/step - loss: 0.2701 - mse: 0.2701 - msle: 0.0016 - mae: 0.1886 - val_loss: 0.0056 - val_mse: 0.0056 - val_msle: 9.9340e-04 - val_mae: 0.0253\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 253s 507ms/step - loss: 0.0260 - mse: 0.0260 - msle: 0.0016 - mae: 0.1176 - val_loss: 0.0058 - val_mse: 0.0058 - val_msle: 0.0010 - val_mae: 0.0290\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 254s 507ms/step - loss: 0.0216 - mse: 0.0216 - msle: 0.0016 - mae: 0.1041 - val_loss: 0.0052 - val_mse: 0.0052 - val_msle: 9.3428e-04 - val_mae: 0.0236\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 253s 506ms/step - loss: 0.0167 - mse: 0.0167 - msle: 0.0016 - mae: 0.0874 - val_loss: 0.0071 - val_mse: 0.0071 - val_msle: 0.0011 - val_mae: 0.0260\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 253s 506ms/step - loss: 0.0127 - mse: 0.0127 - msle: 0.0016 - mae: 0.0699 - val_loss: 0.0064 - val_mse: 0.0064 - val_msle: 0.0011 - val_mae: 0.0236\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 253s 507ms/step - loss: 0.0103 - mse: 0.0103 - msle: 0.0016 - mae: 0.0538 - val_loss: 0.0058 - val_mse: 0.0058 - val_msle: 0.0011 - val_mae: 0.0153\n",
      "Epoch 6: early stopping\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 599, 1)]          0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 599, 30)           330       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 599, 30)           7230      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 599, 40)           7240      \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 599, 50)           10050     \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 599, 50)           12550     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 599, 50)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 29950)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              30669824  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,708,249\n",
      "Trainable params: 30,708,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/ukdale_models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/ukdale_models/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL SIZE INFO ===\n",
      "Total parameters: 30,708,249\n",
      "Expected model size: ~117.1 MB\n",
      "Input shape: (None, 599, 1)\n",
      "Output shape: (None, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argparse\n",
    "# Allows a model to be trained from the terminal.\n",
    "\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    appliance= args.appliance_name,\n",
    "    batch_size=args.batch_size,\n",
    "    crop=args.crop,\n",
    "    network_type=args.network_type,\n",
    "    training_directory = training_directory,\n",
    "    validation_directory = validation_directory,\n",
    "    save_model_dir=save_model_dir,\n",
    "    epochs=args.epochs,\n",
    "    input_window_length=args.input_window_length,\n",
    "    validation_frequency=args.validation_frequency\n",
    "    patience=3,\n",
    "    min_delta= 1e-6,\n",
    "    #verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "338191bf-6149-4ca3-884c-ef7a9b648416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Trainer at 0x2788f9bb520>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63b943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
